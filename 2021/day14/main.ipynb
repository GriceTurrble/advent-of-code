{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Day 14 - Extended Polymerization\n","\n","https://adventofcode.com/2021/day/14"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","INPUTS = Path(\"input.txt\").read_text().strip().split(\"\\n\")\n","POLY_TEMPLATE = INPUTS[0]\n","PAIR_INSERT_RULES = {}\n","for pair in INPUTS[2:]:\n","    key, val = pair.split(\" -> \")\n","    PAIR_INSERT_RULES[key] = val\n"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["def insertion_step(template: str, rules: dict = PAIR_INSERT_RULES) -> str:\n","    output = template[0]\n","    for i in range(len(template) - 1):\n","        pair = template[i : i + 2]\n","        if pair in rules:\n","            output += rules[pair]\n","        output += pair[-1]\n","    return output\n","\n","\n","def test_insertion():\n","    template = \"NNCB\"\n","    rules = {\n","        \"CH\": \"B\",\n","        \"HH\": \"N\",\n","        \"CB\": \"H\",\n","        \"NH\": \"C\",\n","        \"HB\": \"C\",\n","        \"HC\": \"B\",\n","        \"HN\": \"C\",\n","        \"NN\": \"C\",\n","        \"BH\": \"H\",\n","        \"NC\": \"B\",\n","        \"NB\": \"B\",\n","        \"BN\": \"B\",\n","        \"BB\": \"N\",\n","        \"BC\": \"B\",\n","        \"CC\": \"N\",\n","        \"CN\": \"C\",\n","    }\n","    round1 = insertion_step(template=template, rules=rules)\n","    assert round1 == \"NCNBCHB\"\n","    round2 = insertion_step(template=round1, rules=rules)\n","    assert round2 == \"NBCCNBBBCBHCB\"\n","    round3 = insertion_step(template=round2, rules=rules)\n","    assert round3 == \"NBBBCNCCNBBNBNBBCHBHHBCHB\"\n","    round4 = insertion_step(template=round3, rules=rules)\n","    assert round4 == \"NBBNBNBBCCNBCNCCNBBNBBNBBBNBBNBBCBHCBHHNHCBBCBHCB\"\n","\n","\n","test_insertion()\n"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["least_common=(530, 'S'); most_common=(3505, 'C')\n","Difference: 2975\n"]}],"source":["polymer = POLY_TEMPLATE\n","for _ in range(10):\n","    polymer = insertion_step(template=polymer)\n","\n","chars = set(polymer)\n","counts = []\n","for char in chars:\n","    counts.append((polymer.count(char), char))\n","\n","counts = sorted(counts)\n","least_common = counts[0]\n","most_common = counts[-1]\n","print(f\"{least_common=}; {most_common=}\")\n","\n","diff = most_common[0] - least_common[0]\n","print(f\"Difference: {diff}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Part 2\n","\n","I admit I ducked into the spoilers room on Python Discord for some direction here, as originally I just tried running my original method unchanged 40 times. Silly me forgot that this was an exponential growth problem, so the calculation would start taking several minutes per iteration around the 21st step. If I had let it run til the 40th, it might have kept going for a month and blown up my laptop.\n","\n","The tip I took away was one I really should have thought of before, as I had on Day 6. Despite the arrangement of the problem on the site, the real solution doesn't require each character or pair be unique. Instead, we can just build a mapping of pairs to the number of times those pairs exist in the chain.\n","\n","The trick is that each pair separates into a new set of pairs on each iteration, so the original is not preserved. For a rule of `FP -> N`, for example, the pair `FP` would separate into pairs `FN` and `NP`.\n","\n","With that in mind, generating the set of pairs in the polymer is as simple as preserving the *number* of each unique pair. The easiest way to achieve that, I find, is a `defaultdict(int)`."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["from collections import defaultdict\n","\n","\n","def insertion_step2(\n","    pair_counts: dict[str, int],\n","    rules: dict[str, str] = PAIR_INSERT_RULES,\n",") -> dict[int]:\n","    # Start with an empty set of the pair counts to avoid changing the original\n","    new_pair_counts = defaultdict(int)\n","    for pair, num in pair_counts.items():\n","        if pair in PAIR_INSERT_RULES:\n","            # Generate the two new pairs based on this insertion rule\n","            left, right = pair\n","            insertion = PAIR_INSERT_RULES[pair]\n","            new_pair_counts[left + insertion] += num\n","            new_pair_counts[insertion + right] += num\n","        else:\n","            # On the off chance no conversion rule exists,\n","            # add back the original pair to the new counts\n","            new_pair_counts[pair] += num\n","    return new_pair_counts\n"]},{"cell_type":"markdown","metadata":{},"source":["To start off, the original `POLY_TEMPLATE` also needs to be re-processed into an initial set of pair counts. We do this by iterating through indices and pulling slices into the initial defaultdict:"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["pair_counts = defaultdict(int)\n","for x in range(len(POLY_TEMPLATE) - 1):\n","    pair_counts[POLY_TEMPLATE[x : x + 2]] += 1\n"]},{"cell_type":"markdown","metadata":{},"source":["From there, we can run our calculation, which takes milliseconds again instead of minutes."]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["ITERATIONS = 40\n","for _ in range(ITERATIONS):\n","    pair_counts = insertion_step2(pair_counts=pair_counts)\n"]},{"cell_type":"markdown","metadata":{},"source":["Finally, the character count to find most and least common.\n","\n","Two facts are important to keep in mind when counting with this method:\n","\n","1. For every pair in the `pair_counts`, only **one** character of each pairing is the unique character; the other is shared with some other pairing, though we don't keep track of ordering, so we can't be sure of which one.\n","2. Both the **first** and **last** characters of the final polymer will always be the same as the first and last of the initial template.\n","\n","Given this, I chose to consider the **first** character of the template along with every **last** character of the final pairs, in order to count unique characters throughout the polymer.\n","\n","With that in hand, we just sum the values of the pair counts."]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["least_common=(594452039903, 'S'), most_common=(3609835890592, 'C')\n","Difference: 3015383850689\n"]}],"source":["char_counts = defaultdict(int)\n","# Add on the first character of the template, as that will always be present\n","char_counts[POLY_TEMPLATE[0]] += 1\n","for pair, count in pair_counts.items():\n","    # Add on the LAST letter of each pair only,\n","    # as that will always be the unique character we need to count\n","    char_counts[pair[1]] += count\n","\n","# Sort our character counts by their values to arrange them from least- to most common.\n","sorted_chars = sorted((v, k) for k, v in char_counts.items())\n","\n","# Pull those least and most common characters out of the sorted results\n","least_common, most_common = sorted_chars[0], sorted_chars[-1]\n","print(f\"{least_common=}, {most_common=}\")\n","\n","# Calculate the diff for our solution.\n","diff = most_common[0] - least_common[0]\n","print(f\"Difference: {diff}\")\n"]}],"metadata":{"interpreter":{"hash":"e7f838db54ad0012221f0814f3d2887e05cb79f425c36b1945307b340711ff35"},"kernelspec":{"display_name":"Python 3.10.0 64-bit ('advent-of-code-JVQZr3dM': pipenv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
