{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Day 16 - Packet Decoder\n","\n","https://adventofcode.com/2021/day/16"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","\n","INPUTS = Path(\"input.txt\").read_text().strip()\n"]},{"cell_type":"markdown","metadata":{},"source":["For this challenge, the trick won't really be in evaluating the hex format, but in parsing the bits version. So, let's take care of converting it straight away."]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["hex_to_bits = {\n","    \"0\": \"0000\",\n","    \"1\": \"0001\",\n","    \"2\": \"0010\",\n","    \"3\": \"0011\",\n","    \"4\": \"0100\",\n","    \"5\": \"0101\",\n","    \"6\": \"0110\",\n","    \"7\": \"0111\",\n","    \"8\": \"1000\",\n","    \"9\": \"1001\",\n","    \"A\": \"1010\",\n","    \"B\": \"1011\",\n","    \"C\": \"1100\",\n","    \"D\": \"1101\",\n","    \"E\": \"1110\",\n","    \"F\": \"1111\",\n","}\n","BITS = \"\".join(hex_to_bits[x] for x in INPUTS)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Part 1\n","\n","For this one I'm taking a functional approach, writing individual functions capable of pulling necessary details out of the \"bit stream\" as I'm calling it. The format described in the challenge lends itself to parsing only pieces of the transmission at a time, then acting on the `remaining` bits at a later point.\n","\n","We can't always be certain how big a given packet or sub-packet is going to be, hence we just keep chopping off what we can parse now and dealing with those remainders later. To that end, each of the functions below returns some tuple, with the last portion always being `remaining` for the bits that have not been consumed."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def version_id(bit_stream: str) -> tuple[dict[str, str | int], str]:\n","    \"\"\"Splits `bit_stream` into a tuple of `(version, id, remaining)`.\n","\n","    The `version` and `id` are consumed from the incoming bit stream and converted\n","    to their decimal values. All `remaining` parts are returned unchanged.\n","    \"\"\"\n","    version, type_id, remaining = bit_stream[:3], bit_stream[3:6], bit_stream[6:]\n","    return int(version, base=2), int(type_id, base=2), remaining\n","\n","\n","def literal_value(bit_stream: str) -> tuple[int, str]:\n","    \"\"\"Returns a literal value from a packet.\n","\n","    The packet should already have its version and ID split off\n","    from a prior operation.\n","    \"\"\"\n","    value = \"\"\n","    remaining = bit_stream\n","    while True:\n","        section, remaining = remaining[:5], remaining[5:]\n","        value += section[1:]\n","        if section[0] == \"0\":\n","            break\n","    return int(value, base=2), remaining\n","\n","\n","def operator_packet(bit_stream: str) -> tuple[dict[str, str | int], str]:\n","    \"\"\"Parses the bit stream to return tuple `(data, remaining)`.\n","\n","    `data` contains either key `sub_bit_length`, the length (in bits) of sub-packets;\n","    or `num_packets`, the number of sub-packets that follow.\n","\n","    `remaining` contains the remaining portions of the bit_stream that were\n","    not processed.\n","    \"\"\"\n","    length, remaining = bit_stream[0], bit_stream[1:]\n","    data = {}\n","    if length == \"0\":\n","        # 15 bits represent length in bits of the sub-packets\n","        sub_bit_length, remaining = remaining[:15], remaining[15:]\n","        data[\"sub_bit_length\"] = int(sub_bit_length, base=2)\n","    else:\n","        # 11 bits represent number of sub-packets\n","        num_packets, remaining = remaining[:11], remaining[11:]\n","        data[\"num_packets\"] = int(num_packets, base=2)\n","    return data, remaining\n"]},{"cell_type":"markdown","metadata":{},"source":["Now we can get down to the business of parsing the data. Because we're dealing with sub-packets and potentially sub-sub-packets, we need to think recursively, handling as much as we can, pulling whole packet sections out to deal with at a time, and passing the remaining bits back up to be dealt with later (similar to the parsing functions used above)."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["from typing import Any\n","\n","\n","def get_packet_data(bit_stream: str) -> dict[str, Any]:\n","    if len(set(bit_stream)) < 2:\n","        return None, None\n","    version, type_id, remaining = version_id(bit_stream=bit_stream)\n","    packet = {\n","        \"version\": version,\n","        \"type_id\": type_id,\n","    }\n","    if type_id == 4:\n","        packet[\"data\"], remaining = literal_value(remaining)\n","    else:\n","        data, remaining = operator_packet(remaining)\n","        packet[\"sub_packets\"] = []\n","        if \"sub_bit_length\" in data:\n","            # length type 0 got us here. We need to chop off a chunk of the remaining\n","            # into the set of \"packets\" we need to work on, then consume them individually\n","            # until the entire stream is empty (ending in a few leftover 0 bits, that is)\n","            length = data[\"sub_bit_length\"]\n","            packets, remaining = remaining[:length], remaining[length:]\n","            while packets is not None and set(packets) != {\"0\"}:\n","                sub_packet, packets = get_packet_data(bit_stream=packets)\n","                if sub_packet is not None:\n","                    packet[\"sub_packets\"].append(sub_packet)\n","        elif \"num_packets\" in data:\n","            # length type 1, indicating a number of packets of arbitrary length.\n","            # We just need to iterate a number of times equal to num packets\n","            # and process individual packets recursively.\n","            for _ in range(data[\"num_packets\"]):\n","                sub_packet, remaining = get_packet_data(bit_stream=remaining)\n","                if sub_packet is not None:\n","                    packet[\"sub_packets\"].append(sub_packet)\n","    return packet, remaining\n","\n","\n","# Get our packet data and ignore \"remaining\", which will be None anyway.\n","PACKETS, _ = get_packet_data(BITS)\n"]},{"cell_type":"markdown","metadata":{},"source":["Now `PACKETS` contains the completely-parsed data from the bit stream into a Python object, namely a dict which may contain lists of other dicts of the same basic structure.\n","\n","(Sure, I could have written a class to contain this data, but I got lazy.)\n","\n","The actual challenge of Part 1 is to sum all the versions from all packets and sub-packets. For that we need to recursively go over our `PACKETS` and pull up the `version` keys at every level."]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[],"source":["def get_versions(packet: dict[str, Any]) -> int:\n","    version = packet[\"version\"]\n","    sub_packets = packet.get(\"sub_packets\", [])\n","    version += sum([get_versions(packet=x) for x in sub_packets])\n","    return version\n"]},{"cell_type":"markdown","metadata":{},"source":["That brings us to our solution:"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sum of versions: 889\n"]}],"source":["version_sum = get_versions(PACKETS)\n","print(f\"Sum of versions: {version_sum}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Part 2\n","\n","For reference, here's the AoC site's description of the type IDs and their meanings (reformatted here for clarity):\n","\n","> Literal values (type ID `4`) represent a single number as described above. The remaining type IDs are more interesting:\n","\n","> - Packets with type ID `0` are **sum** packets - their value is the sum of the values of their sub-packets. If they only have a single sub-packet, their value is the value of the sub-packet.\n","> - Packets with type ID `1` are **product** packets - their value is the result of multiplying together the values of their sub-packets. If they only have a single sub-packet, their value is the value of the sub-packet.\n","> - Packets with type ID `2` are **minimum** packets - their value is the minimum of the values of their sub-packets.\n","> - Packets with type ID `3` are **maximum** packets - their value is the maximum of the values of their sub-packets.\n","> - Packets with type ID `5` are **greater than** packets - their value is `1` if the value of the first sub-packet is greater than the value of the second sub-packet; otherwise, their value is `0`. These packets always have exactly two sub-packets.\n","> - Packets with type ID `6` are **less than** packets - their value is `1` if the value of the first sub-packet is less than the value of the second sub-packet; otherwise, their value is `0`. These packets always have exactly two sub-packets.\n","> - Packets with type ID `7` are **equal to** packets - their value is `1` if the value of the first sub-packet is equal to the value of the second sub-packet; otherwise, their value is `0`. These packets always have exactly two sub-packets.\n","\n","So, all we need to do is process our already-decoded packet dicts to evaluate the final value. We'll still need a recursive solution, of course, due to the deeply-nested nature of these packets, but that shouldn't be a problem.\n","\n","My approach will be just running a match-case on the `type_id` for a packet, then taking different actions based on those outcomes. Certainly a good excuse to flex the new syntax in Python 3.10. ğŸ˜Š"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["def evaluate_packet(packet: dict[str, Any]) -> int:\n","    sub_packets = packet.get('sub_packets', [])\n","    if packet['type_id'] in (5, 6, 7):\n","        # To make things a little more DRY, we'll evaluate these ones\n","        # early in these cases alone, as we can be sure that only two sub-packets\n","        # exist within these types.\n","        comparisons = [\n","            evaluate_packet(packet=sub_packets[0]),\n","            evaluate_packet(packet=sub_packets[1]),\n","        ]\n","    match packet['type_id']:\n","        case 0:\n","            # Sum\n","            return sum([evaluate_packet(packet=x) for x in sub_packets])\n","        case 1:\n","            # Product\n","            product = 1\n","            for sub_packet in sub_packets:\n","                product *= evaluate_packet(packet=sub_packet)\n","            return product\n","        case 2:\n","            # Minimum\n","            return min([evaluate_packet(packet=x) for x in sub_packets])\n","        case 3:\n","            # Maximum\n","            return max([evaluate_packet(packet=x) for x in sub_packets])\n","        case 4:\n","            # Literal value: return our own 'data' key\n","            return packet['data']\n","        case 5:\n","            # Greater than\n","            # NOTE: int(True) == 1, int(False) == 0.\n","            return int(comparisons[0] > comparisons[1])\n","        case 6:\n","            # Less than\n","            return int(comparisons[0] < comparisons[1])\n","        case 7:\n","            # Equal to\n","            return int(comparisons[0] == comparisons[1])"]},{"cell_type":"markdown","metadata":{},"source":["That all settled, we just need to run it and get our result:"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Value of this transmission: 739303923668\n"]}],"source":["final_value = evaluate_packet(packet=PACKETS)\n","print(f\"Value of this transmission: {final_value}\")"]}],"metadata":{"interpreter":{"hash":"e7f838db54ad0012221f0814f3d2887e05cb79f425c36b1945307b340711ff35"},"kernelspec":{"display_name":"Python 3.10.1 64-bit ('advent-of-code-JVQZr3dM': pipenv)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
